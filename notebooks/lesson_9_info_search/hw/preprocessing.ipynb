{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import io\n",
    "from tqdm import tqdm\n",
    "from itertools import islice\n",
    "import langid\n",
    "import re\n",
    "from concurrent import futures\n",
    "import swifter\n",
    "import asyncio\n",
    "import nltk\n",
    "# import vaex\n",
    "from nltk import  pos_tag\n",
    "from nltk import WordNetLemmatizer\n",
    "import modin.pandas as pdmd\n",
    "from nltk.corpus import stopwords\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "import multiprocessing as mp\n",
    "\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>issue_url</th>\n",
       "      <th>issue_title</th>\n",
       "      <th>body</th>\n",
       "      <th>words_body</th>\n",
       "      <th>words_title</th>\n",
       "      <th>vectors_body</th>\n",
       "      <th>vectors_title</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>\"https://github.com/atais/angular-eonasdan-dat...</td>\n",
       "      <td>manually entered dates issues</td>\n",
       "      <td>i use format 'yyyy-mm-dd' option and bind ng-m...</td>\n",
       "      <td>[becomes, datetimepicker, value, display, mess...</td>\n",
       "      <td>[date, entered, issue, manually]</td>\n",
       "      <td>[-1.0918881048412594, 0.6091022989154856, -0.0...</td>\n",
       "      <td>[-0.1718999730348316, 0.013864445735690257, 0....</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>\"https://github.com/conveyal/analysis-ui/issue...</td>\n",
       "      <td>highlight segment on map when editing speed</td>\n",
       "      <td>when editing the speed of a segment i.e. when ...</td>\n",
       "      <td>[i.e, figure, count, map, edit, either, speed,...</td>\n",
       "      <td>[segment, highlight, map, edit, speed]</td>\n",
       "      <td>[-0.29115673125242214, 0.3148876573334518, -0....</td>\n",
       "      <td>[-0.09172449529209924, 0.6120846510440893, -0....</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>\"https://github.com/Tat5ato/Phantasmic-Mind/is...</td>\n",
       "      <td>concept art for the otherworld</td>\n",
       "      <td>in general, the otherworld is craggy and organ...</td>\n",
       "      <td>[color, making, green, general, dungeon, refer...</td>\n",
       "      <td>[otherworld, art, concept]</td>\n",
       "      <td>[-0.6426295987635459, 0.1959413906015991, -0.6...</td>\n",
       "      <td>[-0.2129118350085444, 0.1997058162846672, 0.08...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>\"https://github.com/qmlweb/qmlweb/issues/420\"</td>\n",
       "      <td>mousearea and touch event in mobile browser</td>\n",
       "      <td>hello, in the master branch, mousearea doesn't...</td>\n",
       "      <td>[therefore, able, handle, browser, mousearea, ...</td>\n",
       "      <td>[touch, mobile, mousearea, browser, event]</td>\n",
       "      <td>[-0.0860627510084977, 0.08294770021710883, -0....</td>\n",
       "      <td>[-0.18239689955900826, 0.11999946835429123, -0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>\"https://github.com/pybel/pybel/issues/174\"</td>\n",
       "      <td>function to drop graph store and edge store, b...</td>\n",
       "      <td>this function should go in the cache manager. ...</td>\n",
       "      <td>[cache, also, cli, expose, manager, graph, man...</td>\n",
       "      <td>[edge, drop, definition, store, graph, function]</td>\n",
       "      <td>[0.023231257312182667, 0.49292497099851956, -0...</td>\n",
       "      <td>[-0.12271752763802979, 0.42897454135271296, -0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9311</th>\n",
       "      <td>\"https://github.com/nextcloud/serverinfo/issue...</td>\n",
       "      <td>settings button gone</td>\n",
       "      <td>when i deselected all kinds of logging entries...</td>\n",
       "      <td>[image, kind, button, ie11, nextcloud, setting...</td>\n",
       "      <td>[setting, button]</td>\n",
       "      <td>[-0.30116717000134485, 0.29315197427729217, -0...</td>\n",
       "      <td>[-0.1860621278884357, 0.08401209127442986, 0.1...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9312</th>\n",
       "      <td>\"https://github.com/WhisperSystems/Signal-Andr...</td>\n",
       "      <td>using without gms</td>\n",
       "      <td>hello, one of my friends have some technical p...</td>\n",
       "      <td>[privacy, register, phone, google, custom, ver...</td>\n",
       "      <td>[without, use]</td>\n",
       "      <td>[-0.276435802930278, -0.30153380350044034, -0....</td>\n",
       "      <td>[-0.14858783265086034, -0.06445682709821797, -...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9313</th>\n",
       "      <td>\"https://github.com/automl/auto-sklearn/issues...</td>\n",
       "      <td>no module named 'configspace.io' during import...</td>\n",
       "      <td>i encounter this exception when trying to impo...</td>\n",
       "      <td>[configspace0.4.3, modulenotfounderror, auto-s...</td>\n",
       "      <td>[module, auto-sklearn, configspace.io, import,...</td>\n",
       "      <td>[-0.29316283410664706, 0.6230892342534959, -0....</td>\n",
       "      <td>[-0.17694951733802847, 0.2904565066593103, -0....</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9314</th>\n",
       "      <td>\"https://github.com/gimli-org/gimli/issues/50\"</td>\n",
       "      <td>ship self-testing binaries</td>\n",
       "      <td>all distributed binaries of pygimli windows, c...</td>\n",
       "      <td>[binary, distributed, conda, pg.test, etc, pac...</td>\n",
       "      <td>[binary, self-testing, ship]</td>\n",
       "      <td>[-0.0914759509305484, 0.4487135361928359, -0.4...</td>\n",
       "      <td>[0.3160170426419626, 0.2812387900777582, -0.13...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9315</th>\n",
       "      <td>\"https://github.com/brython-dev/brython/issues...</td>\n",
       "      <td>list aliasing correctness issue</td>\n",
       "      <td>python import copy a = 1 ,2,3 b = copy.copy a ...</td>\n",
       "      <td>[copy, copy.copy, print, import, output, pytho...</td>\n",
       "      <td>[list, aliasing, issue, correctness]</td>\n",
       "      <td>[0.2390210406617835, 0.5526597311694244, -0.10...</td>\n",
       "      <td>[-0.3886790177260369, 0.6620581511136504, -0.3...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>9316 rows × 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              issue_url  \\\n",
       "0     \"https://github.com/atais/angular-eonasdan-dat...   \n",
       "1     \"https://github.com/conveyal/analysis-ui/issue...   \n",
       "2     \"https://github.com/Tat5ato/Phantasmic-Mind/is...   \n",
       "3         \"https://github.com/qmlweb/qmlweb/issues/420\"   \n",
       "4           \"https://github.com/pybel/pybel/issues/174\"   \n",
       "...                                                 ...   \n",
       "9311  \"https://github.com/nextcloud/serverinfo/issue...   \n",
       "9312  \"https://github.com/WhisperSystems/Signal-Andr...   \n",
       "9313  \"https://github.com/automl/auto-sklearn/issues...   \n",
       "9314     \"https://github.com/gimli-org/gimli/issues/50\"   \n",
       "9315  \"https://github.com/brython-dev/brython/issues...   \n",
       "\n",
       "                                            issue_title  \\\n",
       "0                         manually entered dates issues   \n",
       "1           highlight segment on map when editing speed   \n",
       "2                        concept art for the otherworld   \n",
       "3           mousearea and touch event in mobile browser   \n",
       "4     function to drop graph store and edge store, b...   \n",
       "...                                                 ...   \n",
       "9311                               settings button gone   \n",
       "9312                                  using without gms   \n",
       "9313  no module named 'configspace.io' during import...   \n",
       "9314                         ship self-testing binaries   \n",
       "9315                    list aliasing correctness issue   \n",
       "\n",
       "                                                   body  \\\n",
       "0     i use format 'yyyy-mm-dd' option and bind ng-m...   \n",
       "1     when editing the speed of a segment i.e. when ...   \n",
       "2     in general, the otherworld is craggy and organ...   \n",
       "3     hello, in the master branch, mousearea doesn't...   \n",
       "4     this function should go in the cache manager. ...   \n",
       "...                                                 ...   \n",
       "9311  when i deselected all kinds of logging entries...   \n",
       "9312  hello, one of my friends have some technical p...   \n",
       "9313  i encounter this exception when trying to impo...   \n",
       "9314  all distributed binaries of pygimli windows, c...   \n",
       "9315  python import copy a = 1 ,2,3 b = copy.copy a ...   \n",
       "\n",
       "                                             words_body  \\\n",
       "0     [becomes, datetimepicker, value, display, mess...   \n",
       "1     [i.e, figure, count, map, edit, either, speed,...   \n",
       "2     [color, making, green, general, dungeon, refer...   \n",
       "3     [therefore, able, handle, browser, mousearea, ...   \n",
       "4     [cache, also, cli, expose, manager, graph, man...   \n",
       "...                                                 ...   \n",
       "9311  [image, kind, button, ie11, nextcloud, setting...   \n",
       "9312  [privacy, register, phone, google, custom, ver...   \n",
       "9313  [configspace0.4.3, modulenotfounderror, auto-s...   \n",
       "9314  [binary, distributed, conda, pg.test, etc, pac...   \n",
       "9315  [copy, copy.copy, print, import, output, pytho...   \n",
       "\n",
       "                                            words_title  \\\n",
       "0                      [date, entered, issue, manually]   \n",
       "1                [segment, highlight, map, edit, speed]   \n",
       "2                            [otherworld, art, concept]   \n",
       "3            [touch, mobile, mousearea, browser, event]   \n",
       "4      [edge, drop, definition, store, graph, function]   \n",
       "...                                                 ...   \n",
       "9311                                  [setting, button]   \n",
       "9312                                     [without, use]   \n",
       "9313  [module, auto-sklearn, configspace.io, import,...   \n",
       "9314                       [binary, self-testing, ship]   \n",
       "9315               [list, aliasing, issue, correctness]   \n",
       "\n",
       "                                           vectors_body  \\\n",
       "0     [-1.0918881048412594, 0.6091022989154856, -0.0...   \n",
       "1     [-0.29115673125242214, 0.3148876573334518, -0....   \n",
       "2     [-0.6426295987635459, 0.1959413906015991, -0.6...   \n",
       "3     [-0.0860627510084977, 0.08294770021710883, -0....   \n",
       "4     [0.023231257312182667, 0.49292497099851956, -0...   \n",
       "...                                                 ...   \n",
       "9311  [-0.30116717000134485, 0.29315197427729217, -0...   \n",
       "9312  [-0.276435802930278, -0.30153380350044034, -0....   \n",
       "9313  [-0.29316283410664706, 0.6230892342534959, -0....   \n",
       "9314  [-0.0914759509305484, 0.4487135361928359, -0.4...   \n",
       "9315  [0.2390210406617835, 0.5526597311694244, -0.10...   \n",
       "\n",
       "                                          vectors_title  \n",
       "0     [-0.1718999730348316, 0.013864445735690257, 0....  \n",
       "1     [-0.09172449529209924, 0.6120846510440893, -0....  \n",
       "2     [-0.2129118350085444, 0.1997058162846672, 0.08...  \n",
       "3     [-0.18239689955900826, 0.11999946835429123, -0...  \n",
       "4     [-0.12271752763802979, 0.42897454135271296, -0...  \n",
       "...                                                 ...  \n",
       "9311  [-0.1860621278884357, 0.08401209127442986, 0.1...  \n",
       "9312  [-0.14858783265086034, -0.06445682709821797, -...  \n",
       "9313  [-0.17694951733802847, 0.2904565066593103, -0....  \n",
       "9314  [0.3160170426419626, 0.2812387900777582, -0.13...  \n",
       "9315  [-0.3886790177260369, 0.6620581511136504, -0.3...  \n",
       "\n",
       "[9316 rows x 7 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "documents = pd.read_pickle('data')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_tfidf(type_tfidf):\n",
    "    dummy_fun = lambda doc: doc\n",
    "    tfidf = TfidfVectorizer(analyzer='word', tokenizer=dummy_fun, preprocessor=dummy_fun, token_pattern=None)\n",
    "\n",
    "    if type_tfidf == 'body':\n",
    "        tfidf.fit(documents.words_body)\n",
    "    elif type_tfidf == 'title':\n",
    "        tfidf.fit(documents.words_title)\n",
    "\n",
    "    return tfidf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tfidf_title = get_tfidf('title')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_14036/2990633138.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      8\u001b[0m   \u001b[1;32mreturn\u001b[0m \u001b[0mdata\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      9\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 10\u001b[1;33m \u001b[0mvecs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mload_vectors\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'crawl-300d-2M.vec'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m1_000_000\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_14036/2990633138.py\u001b[0m in \u001b[0;36mload_vectors\u001b[1;34m(fname, limit)\u001b[0m\n\u001b[0;32m      3\u001b[0m   \u001b[0mn\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0md\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmap\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mint\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfin\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mreadline\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m   \u001b[0mdata\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m{\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 5\u001b[1;33m   \u001b[1;32mfor\u001b[0m \u001b[0mline\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mislice\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfin\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlimit\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      6\u001b[0m     \u001b[0mtokens\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mline\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrstrip\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m' '\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      7\u001b[0m     \u001b[0mdata\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mtokens\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0marray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlist\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmap\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfloat\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtokens\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\Programs\\Anaconda\\lib\\codecs.py\u001b[0m in \u001b[0;36mdecode\u001b[1;34m(self, input, final)\u001b[0m\n\u001b[0;32m    317\u001b[0m         \u001b[1;32mraise\u001b[0m \u001b[0mNotImplementedError\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    318\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 319\u001b[1;33m     \u001b[1;32mdef\u001b[0m \u001b[0mdecode\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfinal\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    320\u001b[0m         \u001b[1;31m# decode input (taking the buffer into account)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    321\u001b[0m         \u001b[0mdata\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbuffer\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0minput\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "def load_vectors(fname, limit):\n",
    "  fin = io.open(fname, 'r', encoding = 'utf-8', newline = '\\n', errors = 'ignore')\n",
    "  n, d = map(int, fin.readline().split())\n",
    "  data = {}\n",
    "  for line in islice(fin, limit):\n",
    "    tokens = line.rstrip().split(' ')\n",
    "    data[tokens[0]] = np.array(list(map(float, tokens[1:])))\n",
    "  return data\n",
    "  \n",
    "vecs = load_vectors('crawl-300d-2M.vec', 1_000_000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_vocab(tfidf):\n",
    "    dim = 300\n",
    "    zero = sum(vecs.values()) / len(vecs)\n",
    "\n",
    "    vocab = np.zeros((len(tfidf.vocabulary_.keys()), dim))\n",
    "    for key in tfidf.vocabulary_.keys():\n",
    "        vocab[tfidf.vocabulary_[key]] = vecs.get(key, zero)\n",
    "    return vocab\n",
    "\n",
    "vocab_title = get_vocab(tfidf_title)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((11228,), (11228, 300))"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tfidf_t.shape, vocab_title.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "import preprocess\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "\n",
    "words = preprocess.preprocessing_text(\"python module\")\n",
    "doc = [-0.4462503948404968, 0.28359947183059475, -0.07101933531597554, -0.12367797319164262, 0.03761754315685056, -0.06284692518912936, -0.17654293345032163, -0.6419672914634875, -0.2189299257473043, -0.09615080152198448, 0.5486512024613589, 1.3031293955204672, 0.17161140372588438, -0.2757281769571222, -0.3623743613876279, 0.20602744161792644, -0.3309238236464494, -0.39950838819438167, 0.11132004487500331, -0.32773019295490435, -0.25156560272558065, -0.25736439535604305, -0.06623616218104483, 0.11857001462848595, -0.2930991895563532, -0.16180646256270967, -0.009082833623809962, 0.5290960011517228, 0.01947972915853923, -0.07653202152835224, -0.12607731433463815, 0.22462154862414332, 0.35970346173360496, -0.3568170237335682, 0.16605134053935297, 0.11287234287202422, 0.14168741375168764, -0.19261765204882875, 0.08416413091988872, 0.07369445692231179, 0.4482754729849256, 0.10014234327636556, -0.21043060902973584, 0.20354034940331145, -0.10077453999313676, -0.20736229942040338, 0.07298041982625857, -0.3064768957546244, 0.18786202204816155, -0.49580216443078073, -0.05295030999517184, 0.17855722764178578, 1.2064420822088482, 0.3877644537984423, 0.3154685502472659, -0.21045614507417218, -0.13129983332077175, -0.391135908821944, -0.07385206945108501, -0.099888671411937, 0.33333537997883816, -0.30011960623619466, -0.3843015228888994, -0.6820061818504362, -0.09119323101618936, -0.017315092805138255, 0.42697285615105685, 0.2541135251914139, -0.048077563531251435, -0.6462392169418902, -0.38349317417969925, 0.4452057538105566, -0.2379425406373532, -0.49735126837629906, -0.013426614078556475, 0.3364422496098475, -1.0077815964446022, 0.05172212186623442, -0.16348465888630392, 0.01871289080921157, 1.2528103734317446, 0.04798193653787757, 0.15059129593682524, -0.4847027269279395, 0.07193476006825869, -0.21903518991767465, -0.13695314960225544, 0.0615593102754291, 0.06609550424777422, -0.02041544100031911, -0.29626383861494665, 0.041291388008033066, 0.03114591482532462, 0.3979555864888097, -0.4261085157481374, 0.13915386845219557, -0.05477021161307617, -0.6110104216976547, -0.6338449431488189, -0.45416655704056885, 0.11316430807474495, -0.026164889153596018, -0.19727305592392788, -0.19052601649102902, 0.12688594686137333, -0.22614650677392306, -0.45684071693922274, 0.22449325361234757, -0.14840223789818735, -0.3843277286390108, -0.47039508050665396, 0.0014631893612278477, -0.0748921053715693, 0.23339013895194885, -1.4909594335281258, 0.20242120929554486, 0.4714638201238134, -0.18672538969364372, -0.18561607038547065, -0.1505848252148848, 0.057870648288659336, -0.15994665173491807, -0.023517680759821538, 0.08892363772286989, 0.1751769629932845, -0.150409811795376, -0.348496180387872, 0.07585780085320178, 0.24967165418602089, -0.009511710104114491, 0.6296908324582355, 0.07138699637223753, -0.4367669236502484, 0.29911378787546117, 0.3643560820635339, -0.2104278209174152, -0.015162670516785208, 0.15079801354346944, 0.30498537861525454, -1.335386411520614, -0.37386890481156865, 0.15013922462583756, -0.2488162429209211, -0.27365286656095283, -0.5271307594282592, -0.25030233037631, -0.1755737118997925, -0.6317080278142716, -0.5878440850411626, -0.01830346269923071, 0.26174565030872543, -0.24003699409201074, -0.3241176016529991, -0.11048190335493015, -0.18805498052928518, -0.14811377710607812, 0.20276498481901475, -0.5005430416519498, -0.17254707487795704, 0.09429991285622571, 1.2523169508659908, -0.26673918978967714, 0.21182723582859692, -0.3772596420883174, -0.24826652111336447, -0.3390941288576281, -0.048802822701150037, 0.8675480518114969, 0.06210854216474165, -0.06525993496900077, 0.1233226390394036, 0.39513263565750045, -0.20565351215339125, -0.21725817630855515, -0.8005896704535393, 0.6170187187814357, -0.03678178449013569, 0.1396462333366266, -0.07785183150385915, -0.05785930363383411, -0.1025612440023526, -0.13513916125913505, -0.018026245347045066, -0.009712135537484633, 0.0709463324727992, 0.32424809598112564, -0.008754439767726597, 0.21081171685392835, 0.2531258439109553, -0.3221054647217262, 0.121732285615354, 0.06928343613141019, -0.2493300768839801, 0.3384620678316325, -0.0017840709677125494, -0.5746172479377677, 0.5290753307371547, -0.12596404812584824, 0.31097193258787215, 0.02242918521906639, 0.0675900584912971, 0.1714681046966384, -0.1390388017823463, -0.3443480321237554, -0.356072307984328, 0.1579152702112735, 0.011650304821917805, 0.23708632947818842, 0.5547649463968651, 0.17741685905262417, -0.2718470092021528, 1.6250489102772545, -0.36477386002382645, -0.1987193947011948, 0.08015038002288395, 0.2135513953958716, -0.09158519104510762, 0.23307520950536098, 0.26472182962466245, 0.02749277230212442, -0.4663035058247127, 0.5373248799603298, -0.18568750773339285, -0.10154893779612736, 0.22247926699080944, 0.05095960274908797, 0.41510040237058715, 0.1599233584219622, -0.19914293569377728, 0.34847288464836407, 0.23198907081847236, 0.421914024198894, -0.036946026472186456, -0.0018398909830824807, 0.15132162678161068, -1.2219093018158407, -0.26306915588326096, 0.07627903886611875, 0.572709783580723, -0.4165952720257992, -0.08501229916884309, 0.1647497249927206, 0.46279749937674197, -0.01671249447149237, 0.12775415467040702, -0.2450165868842343, 0.23663496636234002, 0.33012962618823105, 0.2330782688007993, -0.11640414361588251, -0.14902562160725444, 0.3481982866556055, 0.3255774183117795, -0.6730700735507189, 0.13182643039512332, 0.019358819525428887, 0.21186059651797162, -0.14394896688651773, 0.4142822306311954, -0.24999802938457616, 0.0847207835682903, 0.23063627714866572, 0.03785756285561656, 0.2766775973014874, -0.0430646654834772, 0.15973156548375295, 0.03191305632543997, 0.34343874104443717, -0.5087268874196248, -0.2497241710442983, 0.06440047213356549, -0.13087789552650014, 0.3060017500390421, 0.46694218520528963, 0.1504813274315327, 0.20493340808274735, -0.48849240297667923, 0.3547643541721378, 0.11743462763592713, 0.41117328794876923, 0.08644790088500082, -0.22652471695244789, -0.2624379633850216, -0.15074015458927592, -0.388745529618522, -0.42698118090955706, -0.13154374853397136, 0.28012974325323237, 0.15201499269733043, 0.03565916851335873, 0.13012450292200825, 0.14103290215704517, 0.05334818270175863, 0.2059837191904783, 0.03124287578872662, 0.2817439962452036, -0.008326669020692517, -0.5423750229211063, 0.09667096685713972, 0.04356054957040762]\n",
    "tfidf_t = tfidf_title.transform([words]).toarray().squeeze()\n",
    "\n",
    "vector_title = tfidf_t.dot(vocab_title)\n",
    "\n",
    "# np.array(data.vectors_body.tolist()).dot(vocab_body).tolist()\n",
    "diff_title = cosine_similarity([vector_title], [doc])[0][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6298312876168672"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "diff_title"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(300,)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vector_title.shape\n",
    "np.array(doc).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "diff_title"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Создание масенького датасета из большого"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Нашла я датасет гитхабовских проблем на 2гб"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>issue_url</th>\n",
       "      <th>issue_title</th>\n",
       "      <th>body</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>\"https://github.com/zhangyuanwei/node-images/i...</td>\n",
       "      <td>can't load the addon. issue to: https://github...</td>\n",
       "      <td>can't load the addon. issue to: https://github...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>\"https://github.com/Microsoft/pxt/issues/2543\"</td>\n",
       "      <td>hcl accessibility a11yblocking a11ymas mas4.2....</td>\n",
       "      <td>user experience: user who depends on screen re...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>\"https://github.com/MatisiekPL/Czekolada/issue...</td>\n",
       "      <td>issue 1265: issue 1264: issue 1261: issue 1260...</td>\n",
       "      <td>┆attachments: &lt;a href= https:&amp; x2f;&amp; x2f;githu...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>\"https://github.com/MatisiekPL/Czekolada/issue...</td>\n",
       "      <td>issue 1266: issue 1263: issue 1262: issue 1259...</td>\n",
       "      <td>gitlo = github x trello\\n---\\nthis board is no...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>\"https://github.com/MatisiekPL/Czekolada/issue...</td>\n",
       "      <td>issue 1288: issue 1285: issue 1284: issue 1281...</td>\n",
       "      <td>┆attachments: &lt;a href= https:&amp; x2f;&amp; x2f;githu...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5332148</th>\n",
       "      <td>\"https://github.com/bayborodin/ror-full-3/issu...</td>\n",
       "      <td>создать модуль instancecounter, содержащий сле...</td>\n",
       "      <td>методы класса: - instances, который возвращает...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5332149</th>\n",
       "      <td>\"https://github.com/eclipse/paho.mqtt.java/iss...</td>\n",
       "      <td>at org.eclipse.paho.client.mqttv3.internal.cli...</td>\n",
       "      <td>- bug exists release version 1.1.0 master bran...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5332150</th>\n",
       "      <td>\"https://github.com/rzwitserloot/lombok/issues...</td>\n",
       "      <td>java.lang.linkageerror: loader constraint viol...</td>\n",
       "      <td>java.lang.linkageerror: loader constraint viol...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5332151</th>\n",
       "      <td>\"https://github.com/Gizra/productivity/issues/...</td>\n",
       "      <td>node : pdoexception: sqlstate 40001 : serializ...</td>\n",
       "      <td>view details in rollbar: https://rollbar.com/b...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5332152</th>\n",
       "      <td>\"https://github.com/jacobmischka/coyote-grill/...</td>\n",
       "      <td>uncaught error: { error :{ errors : { domain :...</td>\n",
       "      <td>view details in rollbar: https://rollbar.com/j...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5332153 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                 issue_url  \\\n",
       "0        \"https://github.com/zhangyuanwei/node-images/i...   \n",
       "1           \"https://github.com/Microsoft/pxt/issues/2543\"   \n",
       "2        \"https://github.com/MatisiekPL/Czekolada/issue...   \n",
       "3        \"https://github.com/MatisiekPL/Czekolada/issue...   \n",
       "4        \"https://github.com/MatisiekPL/Czekolada/issue...   \n",
       "...                                                    ...   \n",
       "5332148  \"https://github.com/bayborodin/ror-full-3/issu...   \n",
       "5332149  \"https://github.com/eclipse/paho.mqtt.java/iss...   \n",
       "5332150  \"https://github.com/rzwitserloot/lombok/issues...   \n",
       "5332151  \"https://github.com/Gizra/productivity/issues/...   \n",
       "5332152  \"https://github.com/jacobmischka/coyote-grill/...   \n",
       "\n",
       "                                               issue_title  \\\n",
       "0        can't load the addon. issue to: https://github...   \n",
       "1        hcl accessibility a11yblocking a11ymas mas4.2....   \n",
       "2        issue 1265: issue 1264: issue 1261: issue 1260...   \n",
       "3        issue 1266: issue 1263: issue 1262: issue 1259...   \n",
       "4        issue 1288: issue 1285: issue 1284: issue 1281...   \n",
       "...                                                    ...   \n",
       "5332148  создать модуль instancecounter, содержащий сле...   \n",
       "5332149  at org.eclipse.paho.client.mqttv3.internal.cli...   \n",
       "5332150  java.lang.linkageerror: loader constraint viol...   \n",
       "5332151  node : pdoexception: sqlstate 40001 : serializ...   \n",
       "5332152  uncaught error: { error :{ errors : { domain :...   \n",
       "\n",
       "                                                      body  \n",
       "0        can't load the addon. issue to: https://github...  \n",
       "1        user experience: user who depends on screen re...  \n",
       "2        ┆attachments: <a href= https:& x2f;& x2f;githu...  \n",
       "3        gitlo = github x trello\\n---\\nthis board is no...  \n",
       "4        ┆attachments: <a href= https:& x2f;& x2f;githu...  \n",
       "...                                                    ...  \n",
       "5332148  методы класса: - instances, который возвращает...  \n",
       "5332149  - bug exists release version 1.1.0 master bran...  \n",
       "5332150  java.lang.linkageerror: loader constraint viol...  \n",
       "5332151  view details in rollbar: https://rollbar.com/b...  \n",
       "5332152  view details in rollbar: https://rollbar.com/j...  \n",
       "\n",
       "[5332153 rows x 3 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.read_csv(\"github_issues.csv\")\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>issue_url</th>\n",
       "      <th>issue_title</th>\n",
       "      <th>body</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>5332153</td>\n",
       "      <td>5332153</td>\n",
       "      <td>5332153</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>unique</th>\n",
       "      <td>5315477</td>\n",
       "      <td>4862563</td>\n",
       "      <td>5041808</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>top</th>\n",
       "      <td>\"https://github.com/cmty-test/cmty-repository-...</td>\n",
       "      <td>first from flow in uk south</td>\n",
       "      <td>first from flow in uk south</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>freq</th>\n",
       "      <td>297</td>\n",
       "      <td>90133</td>\n",
       "      <td>90133</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                issue_url  \\\n",
       "count                                             5332153   \n",
       "unique                                            5315477   \n",
       "top     \"https://github.com/cmty-test/cmty-repository-...   \n",
       "freq                                                  297   \n",
       "\n",
       "                        issue_title                         body  \n",
       "count                       5332153                      5332153  \n",
       "unique                      4862563                      5041808  \n",
       "top     first from flow in uk south  first from flow in uk south  \n",
       "freq                          90133                        90133  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "slice_data = data.sample(frac=1, random_state=42)[:500_000]\n",
    "slice_data = slice_data.reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "slice_data.to_csv(\"github_issues_slice.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Проведу мини-анализ по ускорению обработки данных\n",
    "\n",
    "Для начала мне нужно выделить из исходного датасета только текст на английском языке (мне так хочется). Для этой задачи уже можно попробовать ускорять"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "def is_en(text):\n",
    "    return text if langid.classify(text)[0] == 'en' else pd.NA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def is_en_md(text):\n",
    "    return text if langid.classify(text)[0] == 'en' else pdmd.NA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "def is_en_bool(text):\n",
    "    return langid.classify(text)[0] == 'en'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### read_csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %%timeit\n",
    "\n",
    "slice_data = pd.read_csv(\"github_issues_slice.csv\")[:1000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %%timeit\n",
    "\n",
    "slice_data_md = pdmd.read_csv(\"github_issues_slice.csv\")[:1000]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Apply by pandas and map"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9.14 s ± 430 ms per loop (mean ± std. dev. of 7 runs, 1 loop each)\n"
     ]
    }
   ],
   "source": [
    "%%timeit\n",
    "\n",
    "to_save = slice_data[slice_data.body.map(is_en_bool)]\n",
    "# slice_data = slice_data[to_save.index]\n",
    "len(to_save)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8.9 s ± 181 ms per loop (mean ± std. dev. of 7 runs, 1 loop each)\n"
     ]
    }
   ],
   "source": [
    "%%timeit\n",
    "\n",
    "res = slice_data.body.apply(is_en)\n",
    "res.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7.18 s ± 139 ms per loop (mean ± std. dev. of 7 runs, 1 loop each)\n"
     ]
    }
   ],
   "source": [
    "%%timeit\n",
    "\n",
    "res = slice_data_md.body.apply(is_en_md)\n",
    "res.dropna()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### future ThreadPoolExecutor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %%timeit\n",
    "\n",
    "with futures.ThreadPoolExecutor() as executor:\n",
    "    res = pd.Series(executor.map(is_en, slice_data.body))\n",
    "    res.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %%timeit\n",
    "\n",
    "with futures.ThreadPoolExecutor() as executor:\n",
    "    res = pdmd.Series(executor.map(is_en_md, slice_data_md.body))\n",
    "    res.dropna()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### future ProcessPoolExecutor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting ProcessPoolExecutor_pd.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile ProcessPoolExecutor_pd.py\n",
    "\n",
    "import pandas as pd\n",
    "import langid\n",
    "import time\n",
    "from concurrent import futures\n",
    "import numpy as np\n",
    "\n",
    "def is_en(text):\n",
    "    return langid.classify(text)[0] == 'en'\n",
    "\n",
    "def process_series(series: pd.Series):\n",
    "    return series.map(is_en)\n",
    "\n",
    "def main(df):\n",
    "    n = 4\n",
    "    parts = np.array_split(df.body, n)\n",
    "\n",
    "    print(\"START TIME\")\n",
    "    start = time.perf_counter()\n",
    "\n",
    "    with futures.ProcessPoolExecutor() as executor:\n",
    "        res = executor.map(process_series, parts)\n",
    "\n",
    "    print(f\"END TIME: {time.perf_counter() - start}\")\n",
    "    print(res)\n",
    "\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    df = pd.read_csv(\"github_issues_slice.csv\")[:1000]\n",
    "\n",
    "    main(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "START TIME\n",
      "END TIME: 10.9749333\n",
      "<generator object _chain_from_iterable_of_lists at 0x000001E022B25740>\n"
     ]
    }
   ],
   "source": [
    "!python ProcessPoolExecutor_pd.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing ProcessPoolExecutor_pdmd.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile ProcessPoolExecutor_pdmd.py\n",
    "\n",
    "import pandas as pd\n",
    "import modin.pandas as pdmd\n",
    "import langid\n",
    "import time\n",
    "from concurrent import futures\n",
    "\n",
    "\n",
    "def is_en(text):\n",
    "    return text if langid.classify(text)[0] == 'en' else pd.NA\n",
    "\n",
    "def main(df):\n",
    "    print(\"START TIME\")\n",
    "    start = time.perf_counter()\n",
    "\n",
    "    with futures.ProcessPoolExecutor() as executor:\n",
    "        res = pdmd.Series(executor.map(is_en, df.body))\n",
    "\n",
    "    print(len(res.dropna()))\n",
    "    print(f\"END TIME: {time.perf_counter() - start}\")\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    df = pdmd.read_csv(\"github_issues_slice.csv\")[:1000]\n",
    "\n",
    "    main(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "!python ProcessPoolExecutor_pdmd.py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### swifter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Pandas Apply: 100%|██████████| 1000/1000 [00:07<00:00, 133.94it/s]\n",
      "Pandas Apply: 100%|██████████| 1000/1000 [00:09<00:00, 109.11it/s]\n",
      "Pandas Apply: 100%|██████████| 1000/1000 [00:07<00:00, 136.19it/s]\n",
      "Pandas Apply: 100%|██████████| 1000/1000 [00:07<00:00, 133.83it/s]\n",
      "Pandas Apply: 100%|██████████| 1000/1000 [00:07<00:00, 141.22it/s]\n",
      "Pandas Apply: 100%|██████████| 1000/1000 [00:07<00:00, 140.44it/s]\n",
      "Pandas Apply: 100%|██████████| 1000/1000 [00:08<00:00, 113.86it/s]\n",
      "Pandas Apply: 100%|██████████| 1000/1000 [00:08<00:00, 111.75it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8.88 s ± 885 ms per loop (mean ± std. dev. of 7 runs, 1 loop each)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "%%timeit\n",
    "\n",
    "res = slice_data.body.swifter.apply(is_en)\n",
    "res.dropna()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Process"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting process_mp.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile process_mp.py\n",
    "\n",
    "import pandas as pd\n",
    "import langid\n",
    "import time\n",
    "from concurrent import futures\n",
    "import numpy as np\n",
    "import multiprocessing as mp\n",
    "\n",
    "\n",
    "def is_en_bool(text):\n",
    "    return langid.classify(text)[0] == 'en'\n",
    "\n",
    "def process_series(series: pd.Series):\n",
    "    return series.map(is_en_bool)\n",
    "\n",
    "def main_n_process(parts):\n",
    "    processes = [\n",
    "        mp.Process(target=process_series, args=(part,))\n",
    "        for part in parts\n",
    "    ]\n",
    "    \n",
    "    for process in processes:\n",
    "        process.start()\n",
    "\n",
    "    print(\"START TIME\")\n",
    "    start = time.perf_counter()\n",
    "    \n",
    "    for process in processes:\n",
    "        process.join()\n",
    "\n",
    "    print(f\"END TIME: {time.perf_counter() - start}\")\n",
    "    return process\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    slice_data = pd.read_csv(\"github_issues_slice.csv\")[:1000]\n",
    "    n = 4\n",
    "    parts = np.array_split(slice_data.body, n)\n",
    "    result = main_n_process(parts)\n",
    "    print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "START TIME\n",
      "END TIME: 7.654426100000002\n",
      "<Process name='Process-4' pid=10088 parent=13892 stopped exitcode=0>\n"
     ]
    }
   ],
   "source": [
    "!python process_mp.py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### vaex"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "dv = vaex.from_csv(\"github_issues_slice.csv\", convert=True, chunk_size=1_000_000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "dv = vaex.open('github_issues_slice.csv.hdf5')[:1000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def is_en(text):\n",
    "    return np.where(langid.classify(text)[0] == 'en', text, np.nan)\n",
    "    # return text if langid.classify(text)[0] == 'en' else np.nan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "dv.body = dv.body.apply(is_en)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 27 s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "1000"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "len(dv.dropna())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "def is_en(text):\n",
    "    return text if langid.classify(text)[0] == 'en' else pd.NA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv(\"github_issues_slice.csv\")[:50_000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with futures.ThreadPoolExecutor() as executor:\n",
    "    data.body = pd.Series(executor.map(is_en, data.body))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6577"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(data[data.body.isnull()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = data.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>issue_url</th>\n",
       "      <th>issue_title</th>\n",
       "      <th>body</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>\"https://github.com/atais/angular-eonasdan-dat...</td>\n",
       "      <td>manually entered dates issues</td>\n",
       "      <td>i use format 'yyyy-mm-dd' option and bind ng-m...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>\"https://github.com/conveyal/analysis-ui/issue...</td>\n",
       "      <td>highlight segment on map when editing speed</td>\n",
       "      <td>when editing the speed of a segment i.e. when ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>\"https://github.com/Tat5ato/Phantasmic-Mind/is...</td>\n",
       "      <td>concept art for the otherworld</td>\n",
       "      <td>in general, the otherworld is craggy and organ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>\"https://github.com/qmlweb/qmlweb/issues/420\"</td>\n",
       "      <td>mousearea and touch event in mobile browser</td>\n",
       "      <td>hello, in the master branch, mousearea doesn't...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>\"https://github.com/pybel/pybel/issues/174\"</td>\n",
       "      <td>function to drop graph store and edge store, b...</td>\n",
       "      <td>this function should go in the cache manager. ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99995</th>\n",
       "      <td>\"https://github.com/aurelia/dialog/issues/288\"</td>\n",
       "      <td>the change dialog-renderer: let click events b...</td>\n",
       "      <td>i'm submitting a bug report operating system: ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99996</th>\n",
       "      <td>\"https://github.com/joyent/triton/issues/231\"</td>\n",
       "      <td>is this project dead?</td>\n",
       "      <td>in looking at some of the outstanding issues w...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99997</th>\n",
       "      <td>\"https://github.com/ARTdrakon/Squad/issues/4\"</td>\n",
       "      <td>nicknames with non utf-8 symbols sometimes inv...</td>\n",
       "      <td>player nickname with non utf-8 symbols sometim...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99998</th>\n",
       "      <td>\"https://github.com/npm/npm/issues/19378\"</td>\n",
       "      <td>run andoid emulator</td>\n",
       "      <td>c:\\users\\user&gt;emulator @nexus_5x_api_27 :error...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99999</th>\n",
       "      <td>\"https://github.com/adobe/brackets/issues/13089\"</td>\n",
       "      <td>mac voice over not working in edit area</td>\n",
       "      <td>prerequisites yes can you reproduce the proble...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>93423 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               issue_url  \\\n",
       "0      \"https://github.com/atais/angular-eonasdan-dat...   \n",
       "1      \"https://github.com/conveyal/analysis-ui/issue...   \n",
       "2      \"https://github.com/Tat5ato/Phantasmic-Mind/is...   \n",
       "3          \"https://github.com/qmlweb/qmlweb/issues/420\"   \n",
       "4            \"https://github.com/pybel/pybel/issues/174\"   \n",
       "...                                                  ...   \n",
       "99995     \"https://github.com/aurelia/dialog/issues/288\"   \n",
       "99996      \"https://github.com/joyent/triton/issues/231\"   \n",
       "99997      \"https://github.com/ARTdrakon/Squad/issues/4\"   \n",
       "99998          \"https://github.com/npm/npm/issues/19378\"   \n",
       "99999   \"https://github.com/adobe/brackets/issues/13089\"   \n",
       "\n",
       "                                             issue_title  \\\n",
       "0                          manually entered dates issues   \n",
       "1            highlight segment on map when editing speed   \n",
       "2                         concept art for the otherworld   \n",
       "3            mousearea and touch event in mobile browser   \n",
       "4      function to drop graph store and edge store, b...   \n",
       "...                                                  ...   \n",
       "99995  the change dialog-renderer: let click events b...   \n",
       "99996                              is this project dead?   \n",
       "99997  nicknames with non utf-8 symbols sometimes inv...   \n",
       "99998                                run andoid emulator   \n",
       "99999            mac voice over not working in edit area   \n",
       "\n",
       "                                                    body  \n",
       "0      i use format 'yyyy-mm-dd' option and bind ng-m...  \n",
       "1      when editing the speed of a segment i.e. when ...  \n",
       "2      in general, the otherworld is craggy and organ...  \n",
       "3      hello, in the master branch, mousearea doesn't...  \n",
       "4      this function should go in the cache manager. ...  \n",
       "...                                                  ...  \n",
       "99995  i'm submitting a bug report operating system: ...  \n",
       "99996  in looking at some of the outstanding issues w...  \n",
       "99997  player nickname with non utf-8 symbols sometim...  \n",
       "99998  c:\\users\\user>emulator @nexus_5x_api_27 :error...  \n",
       "99999  prerequisites yes can you reproduce the proble...  \n",
       "\n",
       "[93423 rows x 3 columns]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = data.reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Обработка данных"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"i use format 'yyyy-mm-dd' option and bind ng-model= formdata.date to my field. now if i enter '2015-03-05aaaaa', the date is displayed as '2015-03-05', but my $scope.formdata.date becomes '2015-03-05aaaaa'. so even if i write error message to user that date is invalid, in input field it looks like totally valid value '2015-03-05'. how do i stop datetimepicker from automatically correcting my dates? this misleads users.\""
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.body[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\daris\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
      "[nltk_data]     C:\\Users\\daris\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
      "[nltk_data]       date!\n",
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     C:\\Users\\daris\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n",
      "[nltk_data] Downloading package omw-1.4 to\n",
      "[nltk_data]     C:\\Users\\daris\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package omw-1.4 is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nltk\n",
    "nltk.download('stopwords')\n",
    "nltk.download('averaged_perceptron_tagger')\n",
    "nltk.download('wordnet')\n",
    "nltk.download('omw-1.4')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sentence segmentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sentence_segmentation(text: str) -> list:\n",
    "    if re.match(r'[\\.!\\?;]', text[-1]):\n",
    "        text = text[:-1]\n",
    "    return re.split(r'[\\.!\\?;]\\s', text.lower())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tokenization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokenization(sentences: list) -> list:\n",
    "    return [re.split(r'[,:(\\s\\-)]*\\s', s) for s in sentences]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Lemmatization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.corpus import wordnet as wn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_wordnet_pos(treebank_tag):\n",
    "    my_switch = {\n",
    "        'J': wn.ADJ,\n",
    "        'V': wn.VERB,\n",
    "        'N': wn.NOUN,\n",
    "        'R': wn.ADV,\n",
    "    }\n",
    "    for key, item in my_switch.items():\n",
    "        if treebank_tag.startswith(key):\n",
    "            return item\n",
    "    return wn.NOUN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def lemmatization(sentences: list) -> list:\n",
    "    sentences_tag  = [pos_tag(s) for s in sentences] # получаем теги слов каждого предложения\n",
    "    \n",
    "    lemmatizer = WordNetLemmatizer()\n",
    "    lemm_sentences = []\n",
    "    for sent in sentences_tag:\n",
    "        pos_tagged = [(word, get_wordnet_pos(tag)) for word, tag in sent]\n",
    "        lemm_sentences.append([lemmatizer.lemmatize(word, tag) for word, tag in pos_tagged])\n",
    "\n",
    "    return lemm_sentences"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Delete stopwords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stop_words = set(stopwords.words('english')).union({'', ' '})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def del_stopwords(sentences: list) -> list:\n",
    "    upd_sentences = []\n",
    "    re_sub = lambda x: re.sub(r\"[\\+=\\t\\r\\n,;:\\*'\\\"]+\",\"\", x)\n",
    "    union_sentences = lambda x: list(set().union(*x))\n",
    "\n",
    "    for sent in sentences:\n",
    "        upd_sentences.append([\n",
    "            re_sub(word) for word in sent if re_sub(word) not in stop_words and len(word) not in [1, 2]\n",
    "        ])\n",
    "    \n",
    "    return union_sentences(upd_sentences)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## All"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocessing_text(text: str) -> list:\n",
    "    return del_stopwords(lemmatization(tokenization(sentence_segmentation(text))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with futures.ThreadPoolExecutor() as executor:\n",
    "    data['words_body'] = pd.Series(executor.map(preprocessing_text, data.body))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with futures.ThreadPoolExecutor() as executor:\n",
    "    data['words_title'] = pd.Series(executor.map(preprocessing_text, data.issue_title))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Vectorization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1000000/1000000 [03:19<00:00, 5005.40it/s]\n"
     ]
    }
   ],
   "source": [
    "def load_vectors(fname, limit):\n",
    "  fin = io.open(fname, 'r', encoding = 'utf-8', newline = '\\n', errors = 'ignore')\n",
    "  n, d = map(int, fin.readline().split())\n",
    "  data = {}\n",
    "  for line in tqdm(islice(fin, limit), total = limit):\n",
    "    tokens = line.rstrip().split(' ')\n",
    "    data[tokens[0]] = np.array(list(map(float, tokens[1:])))\n",
    "  return data\n",
    "\n",
    "vecs = load_vectors('crawl-300d-2M.vec', 1_000_000)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def dummy_fun(doc):\n",
    "    return doc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TfidfVectorizer(preprocessor=<function dummy_fun at 0x000002595E576E50>,\n",
       "                token_pattern=None,\n",
       "                tokenizer=<function dummy_fun at 0x000002595E576E50>)"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tfidf_body = TfidfVectorizer(analyzer='word', tokenizer=dummy_fun, preprocessor=dummy_fun, token_pattern=None)\n",
    "tfidf_body.fit(data.words_body)\n",
    "\n",
    "tfidf_title = TfidfVectorizer(analyzer='word', tokenizer=dummy_fun, preprocessor=dummy_fun, token_pattern=None)\n",
    "tfidf_title.fit(data.words_title)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def vectorization_body(words: list):\n",
    "    return tfidf_body.transform([words]).toarray().squeeze()\n",
    "\n",
    "def vectorization_title(words: list):\n",
    "    return tfidf_title.transform([words]).toarray().squeeze()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "MemoryError",
     "evalue": "bad allocation",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mMemoryError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_15952/3103352145.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;32mwith\u001b[0m \u001b[0mfutures\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mThreadPoolExecutor\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mexecutor\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m     \u001b[0mdata\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'vectors_body'\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mSeries\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mexecutor\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmap\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mvectorization_body\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mwords_body\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32mD:\\Programs\\Anaconda\\lib\\site-packages\\pandas\\core\\series.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, data, index, dtype, name, copy, fastpath)\u001b[0m\n\u001b[0;32m    421\u001b[0m                 \u001b[1;32mpass\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    422\u001b[0m             \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 423\u001b[1;33m                 \u001b[0mdata\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcom\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmaybe_iterable_to_list\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    424\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    425\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mindex\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\Programs\\Anaconda\\lib\\site-packages\\pandas\\core\\common.py\u001b[0m in \u001b[0;36mmaybe_iterable_to_list\u001b[1;34m(obj)\u001b[0m\n\u001b[0;32m    290\u001b[0m     \"\"\"\n\u001b[0;32m    291\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mabc\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mIterable\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mand\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mabc\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mSized\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 292\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mlist\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    293\u001b[0m     \u001b[0mobj\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcast\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mCollection\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mobj\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    294\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mobj\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\Programs\\Anaconda\\lib\\concurrent\\futures\\_base.py\u001b[0m in \u001b[0;36mresult_iterator\u001b[1;34m()\u001b[0m\n\u001b[0;32m    617\u001b[0m                     \u001b[1;31m# Careful not to keep a reference to the popped future\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    618\u001b[0m                     \u001b[1;32mif\u001b[0m \u001b[0mtimeout\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 619\u001b[1;33m                         \u001b[1;32myield\u001b[0m \u001b[0mfs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpop\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mresult\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    620\u001b[0m                     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    621\u001b[0m                         \u001b[1;32myield\u001b[0m \u001b[0mfs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpop\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mresult\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mend_time\u001b[0m \u001b[1;33m-\u001b[0m \u001b[0mtime\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmonotonic\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\Programs\\Anaconda\\lib\\concurrent\\futures\\_base.py\u001b[0m in \u001b[0;36mresult\u001b[1;34m(self, timeout)\u001b[0m\n\u001b[0;32m    442\u001b[0m                     \u001b[1;32mraise\u001b[0m \u001b[0mCancelledError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    443\u001b[0m                 \u001b[1;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_state\u001b[0m \u001b[1;33m==\u001b[0m \u001b[0mFINISHED\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 444\u001b[1;33m                     \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__get_result\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    445\u001b[0m                 \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    446\u001b[0m                     \u001b[1;32mraise\u001b[0m \u001b[0mTimeoutError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\Programs\\Anaconda\\lib\\concurrent\\futures\\_base.py\u001b[0m in \u001b[0;36m__get_result\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    387\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_exception\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    388\u001b[0m             \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 389\u001b[1;33m                 \u001b[1;32mraise\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_exception\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    390\u001b[0m             \u001b[1;32mfinally\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    391\u001b[0m                 \u001b[1;31m# Break a reference cycle with the exception in self._exception\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\Programs\\Anaconda\\lib\\concurrent\\futures\\thread.py\u001b[0m in \u001b[0;36mrun\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m     55\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     56\u001b[0m         \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 57\u001b[1;33m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     58\u001b[0m         \u001b[1;32mexcept\u001b[0m \u001b[0mBaseException\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mexc\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     59\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfuture\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mset_exception\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mexc\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_15952/3976671121.py\u001b[0m in \u001b[0;36mvectorization_body\u001b[1;34m(words)\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;32mdef\u001b[0m \u001b[0mvectorization_body\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mwords\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mlist\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0mtfidf_body\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtransform\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mwords\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtoarray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msqueeze\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      3\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;32mdef\u001b[0m \u001b[0mvectorization_title\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mwords\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mlist\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mtfidf_title\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtransform\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mwords\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtoarray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msqueeze\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\Programs\\Anaconda\\lib\\site-packages\\sklearn\\feature_extraction\\text.py\u001b[0m in \u001b[0;36mtransform\u001b[1;34m(self, raw_documents)\u001b[0m\n\u001b[0;32m   2100\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2101\u001b[0m         \u001b[0mX\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0msuper\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtransform\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mraw_documents\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2102\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_tfidf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtransform\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2103\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2104\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_more_tags\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\Programs\\Anaconda\\lib\\site-packages\\sklearn\\feature_extraction\\text.py\u001b[0m in \u001b[0;36mtransform\u001b[1;34m(self, X, copy)\u001b[0m\n\u001b[0;32m   1675\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1676\u001b[0m             \u001b[1;31m# *= doesn't work\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1677\u001b[1;33m             \u001b[0mX\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mX\u001b[0m \u001b[1;33m*\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_idf_diag\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1678\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1679\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnorm\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\Programs\\Anaconda\\lib\\site-packages\\scipy\\sparse\\base.py\u001b[0m in \u001b[0;36m__mul__\u001b[1;34m(self, other)\u001b[0m\n\u001b[0;32m    478\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m!=\u001b[0m \u001b[0mother\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    479\u001b[0m                 \u001b[1;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'dimension mismatch'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 480\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_mul_sparse_matrix\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mother\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    481\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    482\u001b[0m         \u001b[1;31m# If it's a list or whatever, treat it like a matrix\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\Programs\\Anaconda\\lib\\site-packages\\scipy\\sparse\\compressed.py\u001b[0m in \u001b[0;36m_mul_sparse_matrix\u001b[1;34m(self, other)\u001b[0m\n\u001b[0;32m    520\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    521\u001b[0m         \u001b[0mfn\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0m_sparsetools\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mformat\u001b[0m \u001b[1;33m+\u001b[0m \u001b[1;34m'_matmat'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 522\u001b[1;33m         fn(M, N, np.asarray(self.indptr, dtype=idx_dtype),\n\u001b[0m\u001b[0;32m    523\u001b[0m            \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0masarray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mindices\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0midx_dtype\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    524\u001b[0m            \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mMemoryError\u001b[0m: bad allocation"
     ]
    }
   ],
   "source": [
    "with futures.ThreadPoolExecutor() as executor:\n",
    "    data['vectors_body'] = pd.Series(executor.map(vectorization_body, data.words_body))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with futures.ThreadPoolExecutor() as executor:\n",
    "    data['vectors_title'] = pd.Series(executor.map(vectorization_title, data.words_title))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dim = 300\n",
    "zero = sum(vecs.values()) / len(vecs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 56719/56719 [00:01<00:00, 47862.57it/s]\n"
     ]
    }
   ],
   "source": [
    "vocab_body = np.zeros((len(tfidf_body.vocabulary_.keys()), dim))\n",
    "for key in tqdm(tfidf_body.vocabulary_.keys()):\n",
    "  vocab_body[tfidf_body.vocabulary_[key]] = vecs.get(key, zero)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 11228/11228 [00:00<00:00, 92026.15it/s]\n"
     ]
    }
   ],
   "source": [
    "vocab_title = np.zeros((len(tfidf_title.vocabulary_.keys()), dim))\n",
    "for key in tqdm(tfidf_title.vocabulary_.keys()):\n",
    "  vocab_title[tfidf_title.vocabulary_[key]] = vecs.get(key, zero)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['vectors_body'] = np.array(data.vectors_body.tolist()).dot(vocab_body).tolist()\n",
    "data['vectors_title'] = np.array(data.vectors_title.tolist()).dot(vocab_title).tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.to_pickle(\"data\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "def save_pickle(obj, file):\n",
    "    with open(file, 'wb') as f:\n",
    "        pickle.dump(obj, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_pickle(tfidf_title, \"tfidf_title.pickle\")\n",
    "save_pickle(tfidf_body, \"tfidf_body.pickle\")"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "919eb0904b72c37e8d6c7e3b2f7b6f162c89cafcc297fba09b2d10c79c52f5eb"
  },
  "kernelspec": {
   "display_name": "Python 3.8.8 64-bit ('base': conda)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
