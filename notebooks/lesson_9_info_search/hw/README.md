# DASHA - информационный поиск


[![Видео примера использования](https://img.youtube.com/vi/qGv3UoTFwk4/sddefault.jpg)](https://www.youtube.com/watch?v=qGv3UoTFwk4 "Everything Is AWESOME")

## Датасет

Для поиска я использовала датасет [Github issues](https://www.kaggle.com/davidshinn/github-issues). Мне показалось интересным сделать поиск по проблемам гитхаба. В будущем я бы добавила еще stackoverflow.com.

## Обработка текста

### Мультипроцессинг
Как было сказано в задании, надо было взять датасет примерно на 100мб/миллион записей и обрабатывать его использую мультипроцессинг.

<details>
    <summary> <b> Спойлер </b> </summary>
    У меня не получилось обработать ни миллион записей, ни 100 мб.
</details>

Однако я попыталась, и возможно, дело вовсе не во времени, а в памяти. Она у меня заканчивалась и заканчивалась так же у Google Colab.

Я пыталась разделить массив на несоклько подмассивов, но у меня все равно все крашилось :(

В файле ```preprocessing.ipynb``` я провела мини-анализ на 1000 записях. Что я использовала? 
- ```modin.pandas``` - такой же пандас только быстрее (не всегда)
- ```apply``` и ```map``` от pandas для сравнения
- ```ThreadPoolExecutor```
- ```ProcessPoolExecutor```
- ```swifter```
- ```Process```
- ```vaex``` - неудачная попытка, много мучений с установкой и импортированием, в итоге безрезультатно. Но интересная штука.

Выиграл ```ThreadPoolExecutor``` уменьшив время выполнения по сравнению с apply примерно в 2 раза.

### Сама обработка
Токенизация, лемматизация, векторизация... как всегда.
Векторизировала я с помощью ```word2vec``` и title, и body.

Векторизация мне нужна для того, чтобы сравнивать данный документ с вектором запроса для получения score.

Дополнительно я храню для каждого документа обработанный список слов. Он мне понадобится для того чтобы их посчитать, и в будущем в индексе сортировать именно по количеству этого слова в документах. Так же это может пригодиться если я захочу сортировать по номеру позиции. В общем, по-моему, лишним не будет.

## Ранжирование

Функция score считает косинусной расстояние между вектором запроса и векторами (title, body) документа. Я решила дать разные веса итоговым расстояниям. Неформально получилось так:

$score = 0.4 * cos\_dis(vector\_body, vector\_query) + 0.6 * cos\_dis(vector\_title, vector\_query)$

## Индекс

Я написала свой класс Index, который хранит в себе словарь (повторяюсь, сам индекс) в формате:
```python
{
    'word': {3345, 231, 24, 54}
    ... 
}
```
То есть я реализовала инвертированный индекс с номерами документов. Сами документы хранятся в ```documents``` и эти числа являются индексами в списке ```documents```. Таким образом, очень просто делать пересечение между словами (которое я в retrieve буду использовать), а так же получить сами слова.

Изначально они неотсортированы. Мне показалось это неэффективным. Зачем мне сортировать весь индекс слов, когда я, например, буду использовать не все? Ну, это, возможно в моем случае так. Я отдала предпочтение быстрому запуску поиска, поэтому сортировка по количеству данного слова в документах происходит при возвращении данного слова. 
В любом случае, изменить это не займет много времени.

## Анализ
Функция score измеряет разницу между векторами документа и запроса. В целом, чтобы ее изменить, можно поменять веса у разницы между заголовком и содержанием.

Я использовала precision@k, MAP@k, DCG@k, MRR@k, pFound@k. Все функции находятся в файле ```utils```. Результаты тестирования:
```
query: reduce time bootstrap
<----Average precision at K---->
AP@k = 0.4
<----Discounted cumulative gain at K---->
DCG@k = 2.843396452564766
<----PFound---->
PFound@k = 0.9998937152889662

query: python attributeerror
<----Average precision at K---->
AP@k = 0.5808730158730159
<----Discounted cumulative gain at K---->
DCG@k = 3.193292059500614
<----PFound---->
PFound@k = 0.999990709984186

query: how to import in python
<----Average precision at K---->
AP@k = 0.7763888888888889
<----Discounted cumulative gain at K---->
DCG@k = 2.8862340652624683
<----PFound---->
PFound@k = 0.9999218715240573

query: server doesn't work
<----Average precision at K---->
AP@k = 0.549047619047619
<----Discounted cumulative gain at K---->
DCG@k = 2.766853463455431
<----PFound---->
PFound@k = 0.999862803314499
```
А так же остальные, на всех объектах:
```
<----Mean average precision at k---->
MAP@K = 0.47184126984126984
<----Mean reciprocal rank (MRR) at k---->
MRR@k = 0.825
```

Можно сравнивать результаты на запросах "how to import in python" и "python attributeerror". В первом AP@K выше, чем у второго, однако DCG@k, который как раз учитывает порядок запросов меньше.

В целом, неплохо. Небольшое видео примера показано в видео ```example.mp4```

## Проблемы

Не хочется о них говорить, но все же скажу.

1. Как реагировать на слова, которых нет в индексе? 

Мой выдает ошибку KeyError и я думаю это неправильно. Однако, такой вариант поиска я встретила в приложении SHEIN. Если вбить несуществующие в каталоге слова, то он ничего не может посоветовать\порекомендовать\найти. Если вместо "свитошот" я наберу "свитер", поиск ничего не выдаст. По-моему, это плохое решение проблемы, может в этом случае можно найти синонимы этого слова и поискать в индексе похожее. В приложении H&M поиск работает лучше, понимает, что "свитер" и "свитшот" практически одно и то же, либо выдает самые популярные товары. Возможно, это уже проблема рекомендаций, а не поиска, но все равно было интересно поразмышлять.




