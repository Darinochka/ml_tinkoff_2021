{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Домашнее задание по рекомендательным системам"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "В данном домашнем задании вам предлагается реализовать User-based рекомендательную систему. Так же требуется реализовать несколько вспомогательных функций, шаблоны которых вы можете найти в `utils.py`.\n",
    "\n",
    "Требования к выполнению задания:\n",
    "- Реализация функции из `utils.py` засчитывается, только если пройдены все соответствующие тесты из `test.py`. Запуск тестов: <font color='red'>pytest test.py</font>. Для тестов вам потребуются библиотеки `numpy`, `scipy`, `pytest` и `hypothesis`.\n",
    "- Плагиат запрещен. Если будет замечено, что часть задания списана, то 0 баллов ставится как списывающему, так и давшему списать.\n",
    "- Если пользуетесь кодом из открытых источников, то указывайте ссылки, откуда взяли решение. Иначе такой код может быть воспринят как плагиат.\n",
    "- При выполнении задания нельзя использовать библиотеку `scipy` и функцию `numpy.linalg.norm`\n",
    "\n",
    "При запуске тестов могут появиться предупреждения: PearsonRConstantInputWarning и PearsonRNearConstantInputWarning. На них можно не обращать внимания.\n",
    "\n",
    "Возможный максимум баллов за задание: 10 баллов <br>\n",
    "Дедлайн: ??? <br>\n",
    "Штраф: ??? - будет ли в курсе штраф? <br>\n",
    "<br>\n",
    "Для ускорения проверки, напишите здесь получившееся количество баллов: ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils import euclidean_distance, euclidean_similarity, pearson_similarity, apk, mapk\n",
    "import numpy as np\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(action='ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Метрика сходства\n",
    "<b>1.1. Реализация метрик (2 балла)</b>\n",
    "\n",
    "Первое, с чем необходимо разобраться, при реализации User-based подхода, это с метрикой, с помощью которой будет решаться, насколько похожи пользователи. Вам предлагается реализовать 2 метрики: на основе евклидовой метрики и коэффициент корреляции Пирсона. Шаблоны для обоих функций можете найти в `utils.py`. Не забудьте проверить реализацию на тестах.\n",
    "\n",
    "Евклидова метрика:\n",
    "\\begin{equation}\n",
    "d(p,q)=\\sqrt{(p_1-q_1)^2+(p_2-q_2)^2+\\dots+(p_n-q_n)^2} = \\sqrt{\\sum_{k=1}^n (p_k-q_k)^2}\n",
    "\\end{equation}\n",
    "\n",
    "В этом случае $d(p, q) \\in [0, \\infty)$, при этом если $d(p, q) \\to 0$, то $sim(p, q) \\to 1$. С учетом этого конечная формула будет выглядеть следующим образом:\n",
    "\\begin{equation}\n",
    "sim(p, q) = \\frac{1}{1 + d(p, q)}\n",
    "\\end{equation}\n",
    "Так же в этой формуле не будет проблем с делением на 0.\n",
    "\n",
    "Коэффициент корреляции Пирсона:\n",
    "\\begin{equation}\n",
    "r_{xy} = \\frac {\\sum_{i=1}^{m} \\left( x_i-\\bar{x} \\right)\\left( y_i-\\bar{y} \\right)}{\\sqrt{\\sum_{i=1}^{m} \\left( x_i-\\bar{x} \\right)^2 \\sum_{i=1}^{m} \\left( y_i-\\bar{y} \\right)^2}}\n",
    "\\end{equation}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================= test session starts =============================\n",
      "platform win32 -- Python 3.8.8, pytest-6.2.4, py-1.10.0, pluggy-0.13.1\n",
      "rootdir: d:\\Google\\Projects\\ml_tinkoff_2021\\notebooks\\lesson_10_recommend\\hw\n",
      "plugins: anyio-2.2.0, hypothesis-6.34.2\n",
      "collected 11 items\n",
      "\n",
      "test.py F..........                                                      [100%]\n",
      "\n",
      "================================== FAILURES ===================================\n",
      "___________________________ test_euclidean_distance ___________________________\n",
      "\n",
      "    @given(same_len_lists())\n",
      ">   def test_euclidean_distance(lists):\n",
      "\n",
      "test.py:29: \n",
      "_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n",
      "\n",
      "self = <hypothesis.core.StateForActualGivenExecution object at 0x000001AD1BC3A310>\n",
      "message = 'Hypothesis test_euclidean_distance(lists=[[0.0], [0.0]]) produces unreliable results: Falsified on the first call but did not on a subsequent one'\n",
      "\n",
      "    def __flaky(self, message):\n",
      "        if len(self.falsifying_examples) <= 1:\n",
      ">           raise Flaky(message)\n",
      "E           hypothesis.errors.Flaky: Hypothesis test_euclidean_distance(lists=[[0.0], [0.0]]) produces unreliable results: Falsified on the first call but did not on a subsequent one\n",
      "\n",
      "D:\\Programs\\Anaconda\\lib\\site-packages\\hypothesis\\core.py:886: Flaky\n",
      "--------------------------------- Hypothesis ----------------------------------\n",
      "Falsifying example: test_euclidean_distance(\n",
      "    lists=[[0.0], [0.0]],\n",
      ")\n",
      "Unreliable test timings! On an initial run, this test took 287.36ms, which exceeded the deadline of 200.00ms, but on a subsequent run it took 0.30 ms, which did not. If you expect this sort of variability in your test timings, consider turning deadlines off for this test by setting deadline=None.\n",
      "============================== warnings summary ===============================\n",
      "..\\..\\..\\..\\..\\..\\Programs\\Anaconda\\lib\\site-packages\\pyreadline\\py3k_compat.py:8\n",
      "  D:\\Programs\\Anaconda\\lib\\site-packages\\pyreadline\\py3k_compat.py:8: DeprecationWarning: Using or importing the ABCs from 'collections' instead of from 'collections.abc' is deprecated since Python 3.3, and in 3.9 it will stop working\n",
      "    return isinstance(x, collections.Callable)\n",
      "\n",
      "test.py::test_pearson_similarity\n",
      "  d:\\Google\\Projects\\ml_tinkoff_2021\\notebooks\\lesson_10_recommend\\hw\\utils.py:38: RuntimeWarning: invalid value encountered in double_scalars\n",
      "    return np.sum((x - x.mean()) * (y - y.mean())) / np.sqrt(f(x) * f(y))\n",
      "\n",
      "test.py::test_pearson_similarity\n",
      "  D:\\Programs\\Anaconda\\lib\\site-packages\\scipy\\stats\\stats.py:4023: PearsonRConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n",
      "    warnings.warn(PearsonRConstantInputWarning())\n",
      "\n",
      "-- Docs: https://docs.pytest.org/en/stable/warnings.html\n",
      "=========================== short test summary info ===========================\n",
      "FAILED test.py::test_euclidean_distance - hypothesis.errors.Flaky: Hypothesis...\n",
      "================== 1 failed, 10 passed, 3 warnings in 9.18s ===================\n",
      "============================= test session starts =============================\n",
      "platform win32 -- Python 3.8.8, pytest-6.2.4, py-1.10.0, pluggy-0.13.1\n",
      "rootdir: d:\\Google\\Projects\\ml_tinkoff_2021\\notebooks\\lesson_10_recommend\\hw\n",
      "plugins: anyio-2.2.0, hypothesis-6.34.2\n",
      "collected 11 items\n",
      "\n",
      "test.py ...........                                                      [100%]\n",
      "\n",
      "============================== warnings summary ===============================\n",
      "..\\..\\..\\..\\..\\..\\Programs\\Anaconda\\lib\\site-packages\\pyreadline\\py3k_compat.py:8\n",
      "  D:\\Programs\\Anaconda\\lib\\site-packages\\pyreadline\\py3k_compat.py:8: DeprecationWarning: Using or importing the ABCs from 'collections' instead of from 'collections.abc' is deprecated since Python 3.3, and in 3.9 it will stop working\n",
      "    return isinstance(x, collections.Callable)\n",
      "\n",
      "test.py::test_pearson_similarity\n",
      "  d:\\Google\\Projects\\ml_tinkoff_2021\\notebooks\\lesson_10_recommend\\hw\\utils.py:38: RuntimeWarning: invalid value encountered in double_scalars\n",
      "    return np.sum((x - x.mean()) * (y - y.mean())) / np.sqrt(f(x) * f(y))\n",
      "\n",
      "test.py::test_pearson_similarity\n",
      "  D:\\Programs\\Anaconda\\lib\\site-packages\\scipy\\stats\\stats.py:4023: PearsonRConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n",
      "    warnings.warn(PearsonRConstantInputWarning())\n",
      "\n",
      "-- Docs: https://docs.pytest.org/en/stable/warnings.html\n",
      "======================= 11 passed, 3 warnings in 9.92s ========================\n"
     ]
    }
   ],
   "source": [
    "!pytest test.py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>1.2. (1 балл)</b>\n",
    "\n",
    "Рассмотрим пользователей $u$ и $v$. Им соотвествуют векторы $x_u$ и $x_v$, где $x_u[i] = r_{ui}$ и $x_v[i] = r_{vi}$. Из лекции известно, что похожесть между векторами $x_u$ и $x_v$ вычисляются только для тех индексов i, для которых существует и $r_{ui}$, и $r_{vi}$. То есть верно следуюющее:\n",
    "\\begin{equation}\n",
    "sim(u, v) = sim(x_uI_{uv}, x_vI_{uv}),\n",
    "\\end{equation}\n",
    "где $I_{uv} = [i | \\exists r_{ui} \\& \\exists r_{vi}]$. При этом если $I_{uv} = \\emptyset$, то $sim(u, v) \\to -\\infty$.\n",
    "\n",
    "Реализуйте два новых метода, которые переиспользуют написанные вами `euclidean_distance` и `pearson_distance`, добавляющие условия на $x_u$ и $x_v$. Считается, что $x_u[i] = 0$, если $\\nexists r_{ui}$. То же верно для $x_v$.\n",
    "\n",
    "При реализации заданий можно как написать новые функции, так и использовать декораторы."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def intersection_items(f):\n",
    "    def decorator(x: np.array, y: np.array):\n",
    "        indices = np.arange(len(x))\n",
    "        intresec_idx = indices[(x != 0) & (y != 0)]\n",
    "        return f(x[intresec_idx], y[intresec_idx])\n",
    "    return decorator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# your code (ﾉ>ω<)ﾉ :｡･:*:･ﾟ’★,｡･:*:･ﾟ’☆\n",
    "@intersection_items\n",
    "def euclidean_similarity(x: np.array, y: np.array) -> float:\n",
    "    \"\"\"\n",
    "    Calculate euclidean similarity between points x and y\n",
    "    Args:\n",
    "        x, y: two points in Euclidean n-space\n",
    "    Returns:\n",
    "        Similarity between points x and y\n",
    "    \"\"\"\n",
    "    return 1 / (1 + euclidean_distance(x, y))\n",
    "\n",
    "@intersection_items\n",
    "def pearson_similarity(x: np.array, y: np.array) -> float:\n",
    "    \"\"\"\n",
    "    Calculate a Pearson correlation coefficient given 1-D data arrays x and y\n",
    "    Args:\n",
    "        x, y: two points in n-space\n",
    "    Returns:\n",
    "        Pearson correlation between x and y\n",
    "    \"\"\"\n",
    "    f = lambda z: np.sum((z - z.mean()) ** 2)\n",
    "\n",
    "    return np.sum((x - x.mean()) * (y - y.mean())) / np.sqrt(f(x) * f(y))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. User-based method\n",
    "<b>2.1. (3 балла)</b> \n",
    "\n",
    "Реализовать User-based подход, реализовав методы класса `UserBasedRecommendation`, основанного на использовании `NearestNeighbors`. В качестве метрики может для нахождения похожих пользователей может быть использована как евклидова метрика, так и коэффициент корреляции Пирсона.\n",
    "\n",
    "Не забывайте, что `NearestNeighbors` ищет минимум расстояния между элементами, поэтому логично в качестве метрики при инициализации `NearestNeighbors` использовать обратную метрике схожести. То есть такую, что когда $sim(u, v) \\to 1$, то $d(u, v) \\to 0$. Например: $d(u, v) = 1 - sim(u, v)$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neighbors import NearestNeighbors\n",
    "from typing import Optional\n",
    "\n",
    "from collections import Counter\n",
    "\n",
    "\n",
    "class UserBasedRecommendation:\n",
    "    def __init__(self, metric: str = 'euclidean', n_recommendations: int = 5, alpha: float = 0.8):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            metric: name of metric: ['euclidean', 'pearson']\n",
    "            n_recommendations: number of recommendations. Also can be specified self.make_recommendation\n",
    "            alpha: similarity threshold: if sim(u, v) > alpha then u and v are similar\n",
    "        \"\"\"\n",
    "        self.metric = metric\n",
    "        self.n_recommend = n_recommendations\n",
    "        self.threshold = alpha\n",
    "\n",
    "    def fit(self, X: np.array):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            X: matrix N x M where X[u, i] = r_{ui} if r_{ui} exists else X[u, i] = 0\n",
    "        \"\"\"\n",
    "        self.X = X\n",
    "        self.neighbors = NearestNeighbors(metric=self.distance, radius=self.threshold)\n",
    "        self.neighbors.fit(self.X)\n",
    "\n",
    "    def __find_closest_users(self, user_id: int, n_closest_users: int):\n",
    "        closer_users = self.neighbors.radius_neighbors(\n",
    "            X=[self.X[user_id]], \n",
    "            sort_results=True\n",
    "        )\n",
    "\n",
    "        return closer_users[1][:n_closest_users][0]\n",
    "\n",
    "    def make_recommendation(self, user_id: int, n_recommendations: Optional[int] = None, n_neighbors: int = 2, verbose=True):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            user_id: user id to whom you want to recommend\n",
    "            n_recommendations: number of recommendations\n",
    "        \"\"\"\n",
    "        if n_recommendations is not None:\n",
    "            self.n_recommend = n_recommendations\n",
    "\n",
    "        users_closer = self.__find_closest_users(user_id, n_neighbors)\n",
    "\n",
    "        if verbose:\n",
    "            print(f\"{n_neighbors} neighbours of {user_id}: {users_closer}\")\n",
    "\n",
    "        # создаем маску, означающая 1 если товар куплен и 0 в противном случае\n",
    "        mask_items = self.X[users_closer, :] != 0\n",
    "\n",
    "        # преобразуем в формат чисел и суммируем (то есть для каждого товара количество покупок)\n",
    "        num_items = mask_items.astype(int) if n_neighbors == 1 else mask_items.astype(int).sum(0)\n",
    "\n",
    "        # сортируем, тем самым находим самые популярные товары у данного типа пользователей\n",
    "        return np.argsort(num_items / len(users_closer)).squeeze()[::-1][:self.n_recommend]\n",
    "\n",
    "    def distance(self, x: np.array, y: np.array):\n",
    "        if self.metric == 'euclidean':\n",
    "            return 1 - euclidean_similarity(x, y)\n",
    "        elif self.metric == 'pearson':\n",
    "            return 1 - pearson_similarity(x, y)\n",
    "        else:\n",
    "            raise ValueError(\"You can only use metrics 'euclidean' or 'pearson'\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Хотим сделать рекомендации для фиксированного пользователя $u_{0}$ Найдем множество $U(u_{0})$ пользователей, похожих на данного:\n",
    "\\begin{equation}\n",
    "U(u_{0}) = {u \\in U|sim(u_{0}, u) > \\alpha}\n",
    "\\end{equation}\n",
    "За это отвечает `NearestNeighbors`. $\\alpha$ я не меняла, так как если $sim(u, v) > \\alpha$, то $distance < alpha$, таким образом radius = alpha\n",
    "\n",
    "После этого для каждого товара вычислим, как часто пользователи из множества $U(u_{0})$ покупали его:\n",
    "\\begin{equation}\n",
    "p_{i} = \\frac{|\\{u \\in U(u_{0})|\\exist r_{ui}\\}|}{|U(u_{0}|}\n",
    "\\end{equation}\n",
    "\n",
    "Далее сортируем в порядке убывания и выбираем заданное количество рекомендаций.\n",
    "\n",
    "**Источник**\n",
    "Из конспекта"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>2.2. (1 балла)</b>\n",
    "\n",
    "Приведите пример, для которого использование разных метрик будет давать разные рекомендации. Объясните свой пример."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# your code (ﾉ>ω<)ﾉ :｡･:*:･ﾟ’★,｡･:*:･ﾟ’☆\n",
    "X = np.array([\n",
    "    [3, 4, 8, 9],\n",
    "    [3, 5, 0, 3], # 1 user_id\n",
    "    [8, 7, 6, 2], # 2\n",
    "    [8, 6, 1, 5], # 3\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2 neighbours of 3: [3 1]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([3, 1], dtype=int64)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "recommend = UserBasedRecommendation(metric='euclidean', n_recommendations=2, alpha=0.85)\n",
    "recommend.fit(X)\n",
    "recommend.make_recommendation(user_id=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2 neighbours of 3: [3 2]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([3, 2], dtype=int64)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "recommend = UserBasedRecommendation(metric='pearson', n_recommendations=2, alpha=0.85)\n",
    "recommend.fit(X)\n",
    "recommend.make_recommendation(user_id=3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Объяснение:** рекомендации пользователю с user_id 3 (пронумеровали пользователей и товары от 0) у евклидовой метрики и коэффициент корреляции Пирсона различный, так как и соседи тоже различны. У каждого есть пользователь 3 (то есть пользователь больше всего похож на самого себя). Расмотрим каждый алгоритм по отдельности:\n",
    "- у евклидовой метрики в рекомендациях следует пользователь user_id 1. Если посмотреть на товары, то первый user дал 0-ому товару оценку ниже, чем 1-ому, а у третьего пользователя ситуация обстоит иначе. Более того, третий пользователь купил 2 товар, а первый отказался.\n",
    "- коэффициент корреляции Пирсона учитывает эти различия, поэтому для третьего пользователя соседом является 2 пользователь.\n",
    "\n",
    "**Выводы**\n",
    "Евклидова метрика не учитвает различия между оценками для каждого товара, у него учитывается просто общая сумма различий. Коэффициент корреляции Пирсона более чувствителен к таким особенностям."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Оценка качества\n",
    "<b>3.1. (1 балл)</b>\n",
    "\n",
    "Реализуйте Average Precision at k и Mean Average Precision at k. Шаблоны можете найти в `utils.py`.\n",
    "\\begin{align*}\n",
    "AP@K = \\frac{1}{m}\\sum_{k=1}^K P(k)*rel(k), \\\\\n",
    "MAP@K = \\frac{1}{|U|}\\sum_{u=1}^{|U|}(AP@K)_u\n",
    "\\end{align*}\n",
    "где $P(k)$ - Precision at k, $rel(k) = 1$, если рекомендация релевантна, иначе $rel(k) = 0$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================= test session starts =============================\n",
      "platform win32 -- Python 3.8.8, pytest-6.2.4, py-1.10.0, pluggy-0.13.1\n",
      "rootdir: d:\\Google\\Projects\\ml_tinkoff_2021\\notebooks\\lesson_10_recommend\\hw\n",
      "plugins: anyio-2.2.0, hypothesis-6.34.2\n",
      "collected 11 items\n",
      "\n",
      "test.py ...........                                                      [100%]\n",
      "\n",
      "============================== warnings summary ===============================\n",
      "..\\..\\..\\..\\..\\..\\Programs\\Anaconda\\lib\\site-packages\\pyreadline\\py3k_compat.py:8\n",
      "  D:\\Programs\\Anaconda\\lib\\site-packages\\pyreadline\\py3k_compat.py:8: DeprecationWarning: Using or importing the ABCs from 'collections' instead of from 'collections.abc' is deprecated since Python 3.3, and in 3.9 it will stop working\n",
      "    return isinstance(x, collections.Callable)\n",
      "\n",
      "test.py::test_pearson_similarity\n",
      "  d:\\Google\\Projects\\ml_tinkoff_2021\\notebooks\\lesson_10_recommend\\hw\\utils.py:38: RuntimeWarning: invalid value encountered in double_scalars\n",
      "    return np.sum((x - x.mean()) * (y - y.mean())) / np.sqrt(f(x) * f(y))\n",
      "\n",
      "test.py::test_pearson_similarity\n",
      "  D:\\Programs\\Anaconda\\lib\\site-packages\\scipy\\stats\\stats.py:4023: PearsonRConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n",
      "    warnings.warn(PearsonRConstantInputWarning())\n",
      "\n",
      "-- Docs: https://docs.pytest.org/en/stable/warnings.html\n",
      "======================= 11 passed, 3 warnings in 9.64s ========================\n"
     ]
    }
   ],
   "source": [
    "!pytest test.py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Применение модели\n",
    "<b>4.1. (2 балла)</b>\n",
    "\n",
    "Выгрузите датасет `ratings_small.csv`: https://www.kaggle.com/rounakbanik/the-movies-dataset#ratings_small.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(100004, 4)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.read_csv('ratings_small.csv', index_col=False)\n",
    "data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 671, 671)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.userId.min(), data.userId.max(), len(data.userId.unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 163949, 9066)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.movieId.min(), data.movieId.max(), len(data.movieId.unique())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Для простоты работы с данными, измените нумерацию пользователей и фильмов так, чтобы нумерация начиналась с 0 и шла непрерывно."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# your code (ﾉ>ω<)ﾉ :｡･:*:･ﾟ’★,｡･:*:･ﾟ’☆\n",
    "user_to_idx = {user_id : idx for idx, user_id in enumerate(data.userId.unique())}\n",
    "movie_to_idx = {movie_id : idx for idx, movie_id in enumerate(data.movieId.unique())}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "replacing_user = lambda x: user_to_idx[x]\n",
    "replacing_movie = lambda x: movie_to_idx[x]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.userId = data.userId.apply(replacing_user)\n",
    "data.movieId = data.movieId.apply(replacing_movie)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0, 670, 671)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.userId.min(), data.userId.max(), len(data.userId.unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0, 9065, 9066)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.movieId.min(), data.movieId.max(), len(data.movieId.unique())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Удалим для наиболее активных пользователей 5 оценок"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((99954, 4), (50, 4))"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "active_users = data.userId.value_counts()[:10].index\n",
    "test_data = pd.DataFrame([], columns=data.columns)\n",
    "for user_id in active_users:\n",
    "    _, test = train_test_split(data[data.userId == user_id], test_size=5, random_state=42)\n",
    "    test_data = test_data.append(test, ignore_index=True)\n",
    "    data = data[~((data.userId == user_id) & (data.movieId.isin(test.movieId.values)))]\n",
    "data.shape, test_data.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Преобразуем данные в таблицу `X`, с которой может работать `UserBasedRecommendation`, где $X_{ui} = r_{ui}$, если пользователь $u$ поставил оценку фильму $i$, и $X_{ui} = 0$, если пользователь $u$ не проставил оценку фильму $i$.\n",
    "\n",
    "Вам может пригодиться `csr_matrix`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# your code (ﾉ>ω<)ﾉ :｡･:*:･ﾟ’★,｡･:*:･ﾟ’☆\n",
    "from scipy.sparse import csr_matrix, coo_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "users = data['userId'].values\n",
    "movies = data['movieId'].values\n",
    "rating = data['rating'].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = csr_matrix((rating, (users, movies)), shape=(users.max()+1, movies.max()+1)).todense().A"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[2.5, 3. , 3. , ..., 0. , 0. , 0. ],\n",
       "       [0. , 0. , 0. , ..., 0. , 0. , 0. ],\n",
       "       [0. , 0. , 0. , ..., 0. , 0. , 0. ],\n",
       "       ...,\n",
       "       [0. , 0. , 0. , ..., 0. , 0. , 0. ],\n",
       "       [0. , 0. , 0. , ..., 0. , 0. , 0. ],\n",
       "       [0. , 0. , 0. , ..., 0. , 0. , 0. ]])"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Для пользователей, у которых были удалены фильмы, найдите топ 100 фильмов, который должен посмотреть каждый из этих пользователей, используя `UserBasedRecommendation`. Не забудьте подобрать параметр alpha."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "actual = []\n",
    "for user in active_users:\n",
    "    actual.append(test_data[test_data.userId == user].movieId.values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Int64Index([546, 563, 623, 14, 72, 451, 467, 379, 310, 29], dtype='int64')"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "active_users"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# your code (ﾉ>ω<)ﾉ :｡･:*:･ﾟ’★,｡･:*:･ﾟ’☆\n",
    "def recommendations(metric: str, alpha: int = 0.8, n_neighbors: int = 10):\n",
    "    user_recommend = UserBasedRecommendation(metric=metric, n_recommendations=100, alpha=alpha)\n",
    "    user_recommend.fit(X)\n",
    "\n",
    "    predicted = []\n",
    "    for user in active_users:\n",
    "        predicted.append(user_recommend.make_recommendation(user_id=user, n_neighbors=n_neighbors, verbose=False))\n",
    "    return predicted"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Используя метрику `MAP@5`, `MAP@10` и `MAP@100`, определите, насколько эффективна user-based рекомендательная система для данной задачи."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils import mapk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "def all_mapk(actual, predicted):\n",
    "    print(f\"MAP@5: {mapk(actual, predicted, 5)}\")\n",
    "    print(f\"MAP@10: {mapk(actual, predicted, 10)}\")\n",
    "    print(f\"MAP@100: {mapk(actual, predicted, 100)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Euclidean\n",
      "MAP@5: 0.01\n",
      "MAP@10: 0.005\n",
      "MAP@100: 0.0005\n"
     ]
    }
   ],
   "source": [
    "print(\"Euclidean\")\n",
    "all_mapk(actual, recommendations('euclidean', alpha=0.8))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pearson\n",
      "MAP@5: 0.02\n",
      "MAP@10: 0.01142857142857143\n",
      "MAP@100: 0.0012211553473848557\n"
     ]
    }
   ],
   "source": [
    "print(\"Pearson\")\n",
    "all_mapk(actual, recommendations('pearson', alpha=0.7))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Грустно, результат очень плохой. Причем с увеличением k, map@k уменьшается."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Как можно улучшить работу модели?\n",
    "\n",
    "<b>Ответ:</b> Подобрать гиперпараметры. Например, alpha или количество соседей."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "alphas = np.arange(0, 1, 0.1)\n",
    "n_neighbors = np.arange(5, 100, 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Euclidean\n"
     ]
    }
   ],
   "source": [
    "print(\"Euclidean\")\n",
    "best_alpha = 0\n",
    "best_n = 0\n",
    "best_result = 0\n",
    "for alpha in alphas:\n",
    "    for n in n_neighbors:\n",
    "        predicted = recommendations('euclidean', alpha=alpha, n_neighbors=n)\n",
    "        result = mapk(actual, predicted, 5)\n",
    "        if result > best_result:\n",
    "            best_result = result\n",
    "            best_alpha = alpha\n",
    "            best_n = n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best alpha: 0.9\n",
      "Best n_neighbors: 5\n",
      "Best result: 0.024\n"
     ]
    }
   ],
   "source": [
    "print(f\"Best alpha: {best_alpha}\")\n",
    "print(f\"Best n_neighbors: {best_n}\")\n",
    "print(f\"Best result: {best_result}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pearson\n"
     ]
    }
   ],
   "source": [
    "print(\"Pearson\")\n",
    "best_alpha = 0\n",
    "best_n = 0\n",
    "best_result = 0\n",
    "for alpha in alphas:\n",
    "    for n in n_neighbors:\n",
    "        predicted = recommendations('pearson', alpha=alpha, n_neighbors=n)\n",
    "        result = mapk(actual, predicted, 5)\n",
    "        if result > best_result:\n",
    "            best_result = result\n",
    "            best_alpha = alpha\n",
    "            best_n = n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best alpha: 0.7000000000000001\n",
      "Best n_neighbors: 5\n",
      "Best result: 0.02\n"
     ]
    }
   ],
   "source": [
    "print(f\"Best alpha: {best_alpha}\")\n",
    "print(f\"Best n_neighbors: {best_n}\")\n",
    "print(f\"Best result: {best_result}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Так же я попыталась сама создать функцию нахождения соседей и другой отбор рекомендаций на основе рейтинга. То есть в предыдущем мы учитывали только купил\\не купил, а тут сам рейтинг. ТО есть смотрим, какому товару пользователь поставил бы самый высокий рейтинг. \n",
    "\n",
    "**Источник** Вчера я написала, вкладку закрыла, но где-то на хабре, найти не могу. В целом, эта статья https://habr.com/ru/company/surfingbird/blog/139518/ тоже содержит данную формулу и может являться источником."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neighbors import NearestNeighbors\n",
    "from typing import Optional\n",
    "\n",
    "from collections import Counter\n",
    "\n",
    "\n",
    "class UserBasedRecommendation:\n",
    "    def __init__(self, metric: str = 'euclidean', n_recommendations: int = 5, alpha: float = 0.8):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            metric: name of metric: ['euclidean', 'pearson']\n",
    "            n_recommendations: number of recommendations. Also can be specified self.make_recommendation\n",
    "            alpha: similarity threshold: if sim(u, v) > alpha then u and v are similar\n",
    "        \"\"\"\n",
    "        self.metric = metric\n",
    "        self.n_recommend = n_recommendations\n",
    "        self.threshold = alpha\n",
    "        self.sim = self.define_sim()\n",
    "\n",
    "    def fit(self, X: np.array):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            X: matrix N x M where X[u, i] = r_{ui} if r_{ui} exists else X[u, i] = 0\n",
    "        \"\"\"\n",
    "        self.X = X\n",
    "\n",
    "    def __find_closest_users(self, user_id: int, n_closest_users: int):\n",
    "        closer_users = []\n",
    "        for user in range(self.X.shape[0]):\n",
    "            similarity = self.sim(self.X[user_id], self.X[user])\n",
    "            if similarity > self.threshold:\n",
    "                closer_users.append((similarity, user))\n",
    "\n",
    "        sorted_closer = sorted(closer_users, reverse=True)[:n_closest_users]\n",
    "        return [user for sim, user in sorted_closer]\n",
    "        \n",
    "\n",
    "    def make_recommendation(self, user_id: int, n_recommendations: Optional[int] = None, n_neighbors: int = 2, verbose=True):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            user_id: user id to whom you want to recommend\n",
    "            n_recommendations: number of recommendations\n",
    "        \"\"\"\n",
    "        if n_recommendations is not None:\n",
    "            self.n_recommend = n_recommendations\n",
    "\n",
    "        users_closer = self.__find_closest_users(user_id, n_neighbors)\n",
    "\n",
    "        if verbose:\n",
    "            print(f\"{n_neighbors} neighbours of {user_id}: {users_closer}\")\n",
    "\n",
    "        ratings = []\n",
    "        # среднее для пользователя (учитываем только купленные товары)\n",
    "        mean_user_id = np.mean(self.X[user_id][self.X[user_id] != 0])\n",
    "        \n",
    "        for item in range(self.X.shape[1]):\n",
    "            if self.X[user_id, item] == 0:\n",
    "                temp = []\n",
    "                sum_sim = 0\n",
    "                for user in users_closer:\n",
    "                    similarity = self.sim(self.X[user_id], self.X[user])\n",
    "                    temp.append(similarity * (self.X[user, item] - np.mean(self.X[user])))\n",
    "                    sum_sim += np.abs(similarity)\n",
    "                ratings.append((mean_user_id + np.sum(temp) / sum_sim, item))\n",
    "\n",
    "        sorted_ratings = sorted(ratings, reverse=True)[:self.n_recommend]\n",
    "        return [item for rate, item in sorted_ratings]\n",
    "\n",
    "    def define_sim(self):\n",
    "        if self.metric == 'euclidean':\n",
    "            return euclidean_similarity\n",
    "        elif self.metric == 'pearson':\n",
    "            return pearson_similarity\n",
    "        else:\n",
    "            raise ValueError(\"You can only use metrics 'euclidean' or 'pearson'\")\n",
    "\n",
    "    def distance(self, x: np.array, y: np.array):\n",
    "        return 1 - self.sim(x, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Euclidean\n",
      "MAP@5: 0.0\n",
      "MAP@10: 0.0016666666666666666\n",
      "MAP@100: 0.00025674763832658564\n"
     ]
    }
   ],
   "source": [
    "print(\"Euclidean\")\n",
    "all_mapk(actual, recommendations('euclidean', alpha=0.3, n_neighbors=50))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pearson\n",
      "MAP@5: 0.026666666666666665\n",
      "MAP@10: 0.017499999999999998\n",
      "MAP@100: 0.0019107015021134419\n"
     ]
    }
   ],
   "source": [
    "print(\"Pearson\")\n",
    "all_mapk(actual, recommendations('pearson', alpha=0.2, n_neighbors=50))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
